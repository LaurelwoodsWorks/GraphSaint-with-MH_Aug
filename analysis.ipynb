{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import time\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import json\n",
    "from collections import namedtuple\n",
    "import scipy.sparse\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import dgl\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from scipy.stats import truncnorm\n",
    "import random\n",
    "\n",
    "from torch.profiler import profile, record_function, ProfilerActivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Juyeong.sampler import SAINTNodeSampler, SAINTEdgeSampler, SAINTRandomWalkSampler\n",
    "from Juyeong.modules import GCNNet, AGGNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DEVICE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils.py\n",
    "def load_data(args, multilabel):\n",
    "    prefix = \"data/{}\".format(args.dataset)\n",
    "    DataType = namedtuple('Dataset', ['num_classes', 'train_nid', 'g'])\n",
    "\n",
    "    adj_full = scipy.sparse.load_npz('./{}/adj_full.npz'.format(prefix)).astype(bool)   # np.bool\n",
    "    g = dgl.from_scipy(adj_full)\n",
    "    num_nodes = g.num_nodes()\n",
    "\n",
    "    adj_train = scipy.sparse.load_npz('./{}/adj_train.npz'.format(prefix)).astype(bool) # np.bool\n",
    "    train_nid = np.array(list(set(adj_train.nonzero()[0])))\n",
    "\n",
    "    role = json.load(open('./{}/role.json'.format(prefix)))\n",
    "    mask = np.zeros((num_nodes,), dtype=bool)\n",
    "    train_mask = mask.copy()\n",
    "    train_mask[role['tr']] = True\n",
    "    val_mask = mask.copy()\n",
    "    val_mask[role['va']] = True\n",
    "    test_mask = mask.copy()\n",
    "    test_mask[role['te']] = True\n",
    "\n",
    "    feats = np.load('./{}/feats.npy'.format(prefix))\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(feats[train_nid])\n",
    "    feats = scaler.transform(feats)\n",
    "\n",
    "    class_map = json.load(open('./{}/class_map.json'.format(prefix)))\n",
    "    class_map = {int(k): v for k, v in class_map.items()}\n",
    "    if multilabel:\n",
    "        # Multi-label binary classification\n",
    "        num_classes = len(list(class_map.values())[0])\n",
    "        class_arr = np.zeros((num_nodes, num_classes))\n",
    "        for k, v in class_map.items():\n",
    "            class_arr[k] = v\n",
    "    else:\n",
    "        num_classes = max(class_map.values()) - min(class_map.values()) + 1\n",
    "        class_arr = np.zeros((num_nodes,))\n",
    "        for k, v in class_map.items():\n",
    "            class_arr[k] = v\n",
    "\n",
    "    g.ndata['feat'] = torch.tensor(feats, dtype=torch.float)\n",
    "    g.ndata['label'] = torch.tensor(class_arr, dtype=torch.float if multilabel else torch.long)\n",
    "    g.ndata['train_mask'] = torch.tensor(train_mask, dtype=torch.bool)\n",
    "    g.ndata['val_mask'] = torch.tensor(val_mask, dtype=torch.bool)\n",
    "    g.ndata['test_mask'] = torch.tensor(test_mask, dtype=torch.bool)\n",
    "\n",
    "    data = DataType(g=g, num_classes=num_classes, train_nid=train_nid)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils.py\n",
    "def calc_f1(y_true, y_pred, multilabel):\n",
    "    if multilabel:\n",
    "        y_pred[y_pred > 0] = 1\n",
    "        y_pred[y_pred <= 0] = 0\n",
    "    else:\n",
    "        y_pred = np.argmax(y_pred, axis=1)\n",
    "    return f1_score(y_true, y_pred, average=\"micro\"), \\\n",
    "        f1_score(y_true, y_pred, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils.py\n",
    "def evaluate(model, g, labels, mask, multilabel=False):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(g)\n",
    "        logits = logits[mask]\n",
    "        labels = labels[mask]\n",
    "        f1_mic, f1_mac = calc_f1(labels.cpu().numpy(),\n",
    "                                 logits.cpu().numpy(), multilabel)\n",
    "        return f1_mic, f1_mac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from aug.py\n",
    "\n",
    "class HLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HLoss, self).__init__()\n",
    "\n",
    "    def forward(self, x, full=False):\n",
    "        num_data = x.shape[0]\n",
    "        b = F.softmax(x, dim=1) * F.log_softmax(x, dim=1)\n",
    "        if full:\n",
    "            return -1.0 * b.sum(1)\n",
    "        b = -1.0 * b.sum()\n",
    "        b = b / num_data\n",
    "        return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from aug.py\n",
    "\n",
    "class Jensen_Shannon(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Jensen_Shannon, self).__init__()\n",
    "\n",
    "    def forward(self, y, x):\n",
    "        num_data = x.shape[0]\n",
    "        b = F.softmax(y, dim=1) * F.log_softmax(x, dim=1) - F.softmax(y, dim=1) * F.log_softmax(y, dim=1)\n",
    "        b += F.softmax(x, dim=1) * F.log_softmax(y, dim=1) - F.softmax(x, dim=1) * F.log_softmax(x, dim=1)\n",
    "        b = -0.5 * b.sum()\n",
    "        b = b / num_data\n",
    "        return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from aug.py\n",
    "\n",
    "def our_truncnorm(a, b, mu, sigma, x=None, mode='pdf'):\n",
    "    a, b = (a - mu) / sigma, (b - mu) / sigma\n",
    "    if mode=='pdf':\n",
    "        return truncnorm.pdf(x, a, b, loc = mu, scale = sigma)\n",
    "    elif mode=='rvs':\n",
    "        return truncnorm.rvs(a, b, loc = mu, scale = sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from aug.py\n",
    "\n",
    "def aggregate(graph, agg_model):\n",
    "    s_vec = agg_model(graph)\n",
    "    return s_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from aug.py\n",
    "# NOTE: changed import name of torch as torch (from th)\n",
    "\n",
    "def log_normal(a, b, sigma):\n",
    "    return -1 * torch.pow(a - b, 2) / (2 * torch.pow(sigma, 2)) #/root2pi / sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from aug.py\n",
    "# NOTE: changed import name of torch as torch (from th)\n",
    "\n",
    "def augment(g, delta_G_e, delta_G_v):\n",
    "    num_edge_drop = int(g.num_edges() * delta_G_e)\n",
    "    idx = torch.randperm(num_edge_drop).to(DEVICE)[num_edge_drop:]\n",
    "    g.remove_edges(idx)\n",
    "\n",
    "    n = g.num_nodes()\n",
    "    num_node_drop = int(n * delta_G_v)\n",
    "    aug_feature = g.ndata['feat']\n",
    "    node_list = torch.ones(n, 1).to(DEVICE)\n",
    "    idx = torch.randperm(n).to(DEVICE)[:num_node_drop]\n",
    "    aug_feature[idx] = 0\n",
    "    node_list[idx] = 0\n",
    "    if num_node_drop:\n",
    "        aug_feature *= n / (n - num_node_drop)\n",
    "    g.ndata['feat'] = aug_feature\n",
    "\n",
    "    return g, node_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from aug.py\n",
    "# NOTE: changed import name of torch as torch (from th)\n",
    "\n",
    "def generate_aug_graph(g, model,\n",
    "                       sigma_delta_e=0.03, sigma_delta_v=0.03, mu_e=0.6, mu_v=0.2,\n",
    "                       lam1_e=1, lam1_v=1, lam2_e=0.0, lam2_v=0.0,\n",
    "                       a_e=100, b_e=1, a_v=100, b_v=1):\n",
    "    # Original Graph Feature and Metadata Extraction, Preprocessing\n",
    "    num_nodes = g.num_nodes()\n",
    "    num_edges = g.num_edges()\n",
    "\n",
    "    coo_mat = g.edges(form='uv')\n",
    "    coo_mat = torch.tensor([list(coo_mat[0]), list(coo_mat[1])], device='cuda:0')\n",
    "    n_list = torch.ones(num_nodes)\n",
    "\n",
    "    # Create Aggregate Model\n",
    "    agg_model = AGGNet(num_hop=2)\n",
    "    agg_model.cuda()\n",
    "\n",
    "    i = 0\n",
    "    with profile(activities=[ProfilerActivity.CUDA, ProfilerActivity.CPU], record_shapes=True, profile_memory=True) as prof:\n",
    "        with record_function(\"generate_aug_graph-main_loop\"):\n",
    "            while True:   \n",
    "                i += 1\n",
    "\n",
    "                if i == 1000:\n",
    "                    break\n",
    "                ####################################\n",
    "\n",
    "                # Calculate Delta Value\n",
    "                delta_G_e = 1 - coo_mat.shape[1] / num_edges\n",
    "                delta_G_e_aug = our_truncnorm(0, 1, delta_G_e, sigma_delta_e, mode='rvs')\n",
    "\n",
    "                delta_G_v = 1 - n_list.sum().item() / num_nodes\n",
    "                delta_G_v_aug = our_truncnorm(0, 1, delta_G_v, sigma_delta_v, mode='rvs')\n",
    "\n",
    "                # Graph Augmentation According To Delta Value\n",
    "                aug_g, aug_n_list = augment(g, delta_G_e_aug, delta_G_v_aug)\n",
    "                aug_g = dgl.add_self_loop(aug_g)\n",
    "\n",
    "                # message_passing_g = copy.deepcopy(g)\n",
    "                message_passing_g = g.clone()\n",
    "                message_passing_g.ndata['feat'] = torch.ones(num_nodes, 1, device='cuda:0')\n",
    "\n",
    "                # message_passing_aug_g = copy.deepcopy(aug_g)\n",
    "                message_passing_aug_g = aug_g.clone()\n",
    "                message_passing_aug_g.ndata['feat'] = torch.ones(num_nodes, 1, device='cuda:0')\n",
    "\n",
    "                # Calculate ego-graph's message passing value\n",
    "                with torch.no_grad():\n",
    "                    org_ego = aggregate(message_passing_g, agg_model)\n",
    "\n",
    "                # Calculate Augmented Delta Value\n",
    "                with torch.no_grad():\n",
    "                    delta_g_e = 1 - (aggregate(message_passing_g, agg_model) / org_ego).squeeze(1)\n",
    "                    delta_g_aug_e = 1 - (aggregate(message_passing_aug_g, agg_model) / org_ego).squeeze(1)\n",
    "                    delta_g_v = 1 - (aggregate(message_passing_g, agg_model) / org_ego).squeeze(1)\n",
    "                    delta_g_aug_v = 1 - (aggregate(message_passing_aug_g, agg_model) / org_ego).squeeze(1)\n",
    "\n",
    "                # Calculate Target Distribution and Proposal Distribution\n",
    "                h_loss_op = HLoss()\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    output = model(g)\n",
    "\n",
    "                max_ent = h_loss_op(torch.full((1, output.shape[1]), 1 / output.shape[1])).item()\n",
    "                ent = h_loss_op(output.detach(), True) / max_ent\n",
    "                \n",
    "                # log_normal: normal distribution에 log를 취한 것\n",
    "                p = lam1_e * log_normal(delta_g_e, mu_e, a_e * ent + b_e) + \\\n",
    "                    0\n",
    "                    # lam1_v * log_normal(delta_g_v, mu_v, a_v * ent + b_v)\n",
    "                p_aug = lam1_e * log_normal(delta_g_aug_e, mu_e, a_e * ent + b_e) + \\\n",
    "                    0\n",
    "                    # lam1_v * log_normal(delta_g_aug_v, mu_v, a_v * ent + b_v)\n",
    "\n",
    "                q = np.log(our_truncnorm(0, 1, delta_G_e_aug, sigma_delta_e, x=delta_G_e, mode='pdf')) + \\\n",
    "                    lam2_e * scipy.special.betaln(num_edges - num_edges * delta_G_e + 1, num_edges * delta_G_e + 1) + \\\n",
    "                    np.log(our_truncnorm(0, 1, delta_G_v_aug, sigma_delta_v, x=delta_G_v, mode='pdf')) + \\\n",
    "                    lam2_v * scipy.special.betaln(num_nodes - num_nodes * delta_G_v + 1, num_nodes * delta_G_v + 1)\n",
    "                q_aug = np.log(our_truncnorm(0, 1, delta_G_e, sigma_delta_e, x=delta_G_e_aug, mode='pdf')) + \\\n",
    "                    lam2_e * scipy.special.betaln(num_edges - num_edges * delta_G_e_aug + 1,\n",
    "                                                num_edges * delta_G_e_aug + 1) + \\\n",
    "                    np.log(our_truncnorm(0, 1, delta_G_v, sigma_delta_v, x=delta_G_v_aug, mode='pdf')) + \\\n",
    "                    lam2_v * scipy.special.betaln(num_nodes - num_nodes * delta_G_v_aug + 1, num_nodes * delta_G_v_aug + 1)\n",
    "\n",
    "                # Calculate Acceptance\n",
    "                acceptance = ((torch.sum(p_aug) - torch.sum(p)) - (q_aug - q))\n",
    "                if np.log(random.random()) < acceptance:\n",
    "                    break\n",
    "    \n",
    "    ###########################################################\n",
    "    print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))\n",
    "\n",
    "    with open(\"profiler_record-.txt\", 'w') as result:\n",
    "        result.write(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))\n",
    "    ######################################################\n",
    "\n",
    "\n",
    "    return aug_g, delta_G_e, delta_G_v, delta_G_e_aug, delta_G_v_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into sub functions for profiling.\n",
    "def _generate_aug_graph(g, model,\n",
    "                       sigma_delta_e=0.03, sigma_delta_v=0.03, mu_e=0.6, mu_v=0.2,\n",
    "                       lam1_e=1, lam1_v=1, lam2_e=0.0, lam2_v=0.0,\n",
    "                       a_e=100, b_e=1, a_v=100, b_v=1):\n",
    "\n",
    "    # Original Graph Feature and Metadata Extraction, Preprocessing\n",
    "    def initialize():\n",
    "        num_nodes = g.num_nodes()\n",
    "        num_edges = g.num_edges()\n",
    "\n",
    "        coo_mat = g.edges(form='uv')\n",
    "        coo_mat = torch.tensor([list(coo_mat[0]), list(coo_mat[1])]).to(DEVICE)\n",
    "        n_list = torch.ones(num_nodes).to(DEVICE)\n",
    "\n",
    "        # Create Aggregate Model\n",
    "        agg_model = AGGNet(num_hop=2)\n",
    "        agg_model.cuda()\n",
    "\n",
    "        return num_nodes, num_edges, coo_mat, n_list, agg_model\n",
    "\n",
    "    def calculate_delta_value():\n",
    "        # Calculate Delta Value\n",
    "        delta_G_e = 1 - coo_mat.shape[1] / num_edges\n",
    "        delta_G_e_aug = our_truncnorm(0, 1, delta_G_e, sigma_delta_e, mode='rvs')\n",
    "\n",
    "        delta_G_v = 1 - n_list.sum().item() / num_nodes\n",
    "        delta_G_v_aug = our_truncnorm(0, 1, delta_G_v, sigma_delta_v, mode='rvs')\n",
    "\n",
    "        return delta_G_e, delta_G_e_aug, delta_G_v, delta_G_v_aug  \n",
    "\n",
    "    def graph_augmentation():\n",
    "        # Graph Augmentation According To Delta Value\n",
    "        aug_g, aug_n_list = augment(g, delta_G_e_aug, delta_G_v_aug)\n",
    "        aug_g = dgl.add_self_loop(aug_g)\n",
    "\n",
    "        return aug_g\n",
    "\n",
    "    def message_passing():\n",
    "        # message_passing_g = copy.deepcopy(g)\n",
    "        message_passing_g = g.clone()\n",
    "        message_passing_g.ndata['feat'] = torch.ones(num_nodes, 1).to(DEVICE)\n",
    "\n",
    "        # message_passing_aug_g = copy.deepcopy(aug_g)\n",
    "        message_passing_aug_g = aug_g.clone()\n",
    "        message_passing_aug_g.ndata['feat'] = torch.ones(num_nodes, 1).to(DEVICE)\n",
    "\n",
    "        return message_passing_g, message_passing_aug_g\n",
    "\n",
    "    def calculate_ego_graph_message_passing_value():\n",
    "        # Calculate ego-graph's message passing value\n",
    "        with torch.no_grad():\n",
    "            org_ego = aggregate(message_passing_g, agg_model)\n",
    "\n",
    "        return org_ego\n",
    "\n",
    "    def calculate_augmented_delta():\n",
    "        # Calculate Augmented Delta Value\n",
    "        with torch.no_grad():\n",
    "            delta_g_e = 1 - (aggregate(message_passing_g, agg_model) / org_ego).squeeze(1)\n",
    "            delta_g_aug_e = 1 - (aggregate(message_passing_aug_g, agg_model) / org_ego).squeeze(1)\n",
    "            delta_g_v = 1 - (aggregate(message_passing_g, agg_model) / org_ego).squeeze(1)\n",
    "            delta_g_aug_v = 1 - (aggregate(message_passing_aug_g, agg_model) / org_ego).squeeze(1)\n",
    "\n",
    "        return delta_g_e, delta_g_aug_e, delta_g_v, delta_g_aug_v\n",
    "\n",
    "    def calculate_distribution():\n",
    "        # Calculate Target Distribution and Proposal Distribution\n",
    "        h_loss_op = HLoss()\n",
    "        return h_loss_op\n",
    "\n",
    "    def compute_model():\n",
    "        with torch.no_grad():\n",
    "            output = model(g)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def compute_ent():\n",
    "        max_ent = h_loss_op(torch.full((1, output.shape[1]), 1 / output.shape[1])).item()\n",
    "        ent = h_loss_op(output.detach(), True) / max_ent\n",
    "\n",
    "        return ent\n",
    "\n",
    "    def compute_p_aug():\n",
    "        # log_normal: normal distribution에 log를 취한 것\n",
    "        p = lam1_e * log_normal(delta_g_e, mu_e, a_e * ent + b_e) + \\\n",
    "            0\n",
    "            # lam1_v * log_normal(delta_g_v, mu_v, a_v * ent + b_v)\n",
    "        p_aug = lam1_e * log_normal(delta_g_aug_e, mu_e, a_e * ent + b_e) + \\\n",
    "            0\n",
    "            # lam1_v * log_normal(delta_g_aug_v, mu_v, a_v * ent + b_v)\n",
    "        \n",
    "        return p, p_aug\n",
    "\n",
    "    def compute_q_aug():\n",
    "        q = np.log(our_truncnorm(0, 1, delta_G_e_aug, sigma_delta_e, x=delta_G_e, mode='pdf')) + \\\n",
    "            lam2_e * scipy.special.betaln(num_edges - num_edges * delta_G_e + 1, num_edges * delta_G_e + 1) + \\\n",
    "            np.log(our_truncnorm(0, 1, delta_G_v_aug, sigma_delta_v, x=delta_G_v, mode='pdf')) + \\\n",
    "            lam2_v * scipy.special.betaln(num_nodes - num_nodes * delta_G_v + 1, num_nodes * delta_G_v + 1)\n",
    "        q_aug = np.log(our_truncnorm(0, 1, delta_G_e, sigma_delta_e, x=delta_G_e_aug, mode='pdf')) + \\\n",
    "            lam2_e * scipy.special.betaln(num_edges - num_edges * delta_G_e_aug + 1,\n",
    "                                        num_edges * delta_G_e_aug + 1) + \\\n",
    "            np.log(our_truncnorm(0, 1, delta_G_v, sigma_delta_v, x=delta_G_v_aug, mode='pdf')) + \\\n",
    "            lam2_v * scipy.special.betaln(num_nodes - num_nodes * delta_G_v_aug + 1, num_nodes * delta_G_v_aug + 1)\n",
    "        \n",
    "        return q, q_aug\n",
    "\n",
    "    #-------------------------------------------------------------------------------------------------\n",
    "\n",
    "    with profile(activities=[ProfilerActivity.CUDA, ProfilerActivity.CPU], record_shapes=True, profile_memory=True, on_trace_ready=torch.profiler.tensorboard_trace_handler('./log/flickr')) as prof:\n",
    "        with record_function(\"initialize\"):\n",
    "            num_nodes, num_edges, coo_mat, n_list, agg_model = initialize()\n",
    "\n",
    "        i = 0\n",
    "        while True:   \n",
    "            i += 1\n",
    "\n",
    "            if i == 100:\n",
    "                break\n",
    "            ####################################\n",
    "\n",
    "            with record_function(\"calculate_delta_value\"):\n",
    "                delta_G_e, delta_G_e_aug, delta_G_v, delta_G_v_aug = calculate_delta_value()\n",
    "\n",
    "            with record_function(\"graph_augmentation\"):\n",
    "                aug_g = graph_augmentation()\n",
    "\n",
    "            with record_function(\"message_passing\"):\n",
    "                message_passing_g, message_passing_aug_g = message_passing()\n",
    "\n",
    "            with record_function(\"calculate_ego_graph_message_passing_value\"):\n",
    "                org_ego = calculate_ego_graph_message_passing_value()\n",
    "\n",
    "            with record_function(\"calculate_augmented_delta\"):\n",
    "                delta_g_e, delta_g_aug_e, delta_g_v, delta_g_aug_v = calculate_augmented_delta()\n",
    "\n",
    "            with record_function(\"calculate_distribution\"):\n",
    "                h_loss_op = calculate_distribution()\n",
    "\n",
    "            with record_function(\"compute_model\"):\n",
    "                output = compute_model()   \n",
    "\n",
    "            with record_function(\"compute_ent\"):\n",
    "                ent = compute_ent()\n",
    "\n",
    "            with record_function(\"compute_p_aug\"):\n",
    "                p, p_aug = compute_p_aug()\n",
    "\n",
    "            with record_function(\"compute_q_aug\"):\n",
    "                q, q_aug = compute_q_aug()\n",
    "\n",
    "            # Calculate Acceptance\n",
    "            acceptance = ((torch.sum(p_aug) - torch.sum(p)) - (q_aug - q))\n",
    "            if np.log(random.random()) < acceptance:\n",
    "                break\n",
    "\n",
    "    print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))\n",
    "\n",
    "\n",
    "    return aug_g, delta_G_e, delta_G_v, delta_G_e_aug, delta_G_v_aug    # type:ignore"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config: 'flickr_n'\n",
    "a = {\n",
    "        'aggr': 'concat', 'arch': '1-1-0', 'dataset': 'flickr', 'dropout': 0.2, 'edge_budget': 6000, 'length': 2,\n",
    "        'log_dir': 'none', 'lr': 0.005, 'decay': 0.0005, 'n_epochs': 50, 'n_hidden': 256, 'no_batch_norm': False, 'node_budget': 8000,\n",
    "        'num_subg': 25, 'num_roots': 6000, 'sampler': 'node', 'use_val': True, 'val_every': 1, 'num_workers_sampler': 0,\n",
    "        'num_subg_sampler': 10000, 'batch_size_sampler': 200, 'num_workers': 8, 'full': False,\n",
    "        'sigma_delta_e': 0.03, 'sigma_delta_v': 0.03, 'mu_e': 0.6, 'mu_v': 0.2, 'lam1_e': 1, 'lam1_v': 1, 'lam2_e': 0.0, 'lam2_v': 0.0,\n",
    "        'a_e': 100, 'b_e': 1, 'a_v': 100, 'b_v': 1, 'kl': 2.0, 'h': 0.2, 'online': False, 'gpu': 0\n",
    "}\n",
    "multilabel =  False\n",
    "\n",
    "from collections import namedtuple\n",
    "A = namedtuple('a', a)\n",
    "args = A(**a)\n",
    "\n",
    "if args.dataset in ['amazon']:\n",
    "        cpu_flag = True\n",
    "else:\n",
    "        cpu_flag = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data(args, multilabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset(num_classes=7, train_nid=array([    0,     3,     4, ..., 89246, 89248, 89249]), g=Graph(num_nodes=89250, num_edges=899756,\n",
       "      ndata_schemes={'feat': Scheme(shape=(500,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.int64), 'train_mask': Scheme(shape=(), dtype=torch.bool), 'val_mask': Scheme(shape=(), dtype=torch.bool), 'test_mask': Scheme(shape=(), dtype=torch.bool)}\n",
       "      edata_schemes={}))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Data statistics------'\n",
      "#Nodes 89250\n",
      "#Edges 899756\n",
      "#Classes/Labels (multi binary labels) 7\n",
      "#Train samples 44625\n",
      "#Val samples 22312\n",
      "#Test samples 22313\n"
     ]
    }
   ],
   "source": [
    "# from train_sampling.py\n",
    "g = data.g\n",
    "train_mask = g.ndata['train_mask']\n",
    "val_mask = g.ndata['val_mask']\n",
    "test_mask = g.ndata['test_mask']\n",
    "labels = g.ndata['label']\n",
    "\n",
    "train_nid = data.train_nid\n",
    "\n",
    "in_feats = g.ndata['feat'].shape[1]\n",
    "n_classes = data.num_classes\n",
    "n_nodes = g.num_nodes()\n",
    "n_edges = g.num_edges()\n",
    "\n",
    "n_train_samples = train_mask.int().sum().item()\n",
    "n_val_samples = val_mask.int().sum().item()\n",
    "n_test_samples = test_mask.int().sum().item()\n",
    "\n",
    "print(\"\"\"----Data statistics------'\n",
    "#Nodes %d\n",
    "#Edges %d\n",
    "#Classes/Labels (multi binary labels) %d\n",
    "#Train samples %d\n",
    "#Val samples %d\n",
    "#Test samples %d\"\"\" %\n",
    "        (n_nodes, n_edges, n_classes,\n",
    "        n_train_samples,\n",
    "        n_val_samples,\n",
    "        n_test_samples))\n",
    "# load sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling time: [0.89s]\n",
      "Normalization time: [0.01s]\n",
      "The number of subgraphs is:  200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Laurelwoods\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\dgl\\backend\\pytorch\\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n"
     ]
    }
   ],
   "source": [
    "# from train_sampling.py\n",
    "kwargs = {\n",
    "        'dn': args.dataset, 'g': g, 'train_nid': train_nid, 'num_workers_sampler': args.num_workers_sampler,\n",
    "        'num_subg_sampler': args.num_subg_sampler, 'batch_size_sampler': args.batch_size_sampler,\n",
    "        'online': args.online, 'num_subg': args.num_subg, 'full': args.full}\n",
    "\n",
    "if args.sampler == \"node\":\n",
    "    saint_sampler = SAINTNodeSampler(args.node_budget, **kwargs)\n",
    "elif args.sampler == \"edge\":\n",
    "    saint_sampler = SAINTEdgeSampler(args.edge_budget, **kwargs)\n",
    "elif args.sampler == \"rw\":\n",
    "    saint_sampler = SAINTRandomWalkSampler(args.num_roots, args.length, **kwargs)\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "\n",
    "loader = DataLoader(saint_sampler, collate_fn=saint_sampler.__collate_fn__, batch_size=2**6,\n",
    "                    shuffle=False, num_workers=args.num_workers, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels shape: torch.Size([89250])\n",
      "features shape: torch.Size([89250, 500])\n"
     ]
    }
   ],
   "source": [
    "# from train_sampling.py\n",
    "cpu_flag = False\n",
    "\n",
    "# set device for dataset tensors\n",
    "if args.gpu < 0:\n",
    "    cuda = False\n",
    "else:\n",
    "    cuda = True\n",
    "    torch.cuda.set_device(args.gpu)\n",
    "    val_mask = val_mask.cuda()\n",
    "    test_mask = test_mask.cuda()\n",
    "    if not cpu_flag:\n",
    "        g = g.to(DEVICE)\n",
    "\n",
    "print('labels shape:', g.ndata['label'].shape)\n",
    "print(\"features shape:\", g.ndata['feat'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory allocated before training(MB) 195.70556640625\n"
     ]
    }
   ],
   "source": [
    "# from train_sampling.py\n",
    "model = GCNNet(\n",
    "    in_dim=in_feats,\n",
    "    hid_dim=args.n_hidden,\n",
    "    out_dim=n_classes,\n",
    "    arch=args.arch,\n",
    "    dropout=args.dropout,\n",
    "    batch_norm=not args.no_batch_norm,\n",
    "    aggr=args.aggr\n",
    ")\n",
    "\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "\n",
    "# use optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.decay)\n",
    "\n",
    "# set train_nids to cuda tensor\n",
    "if cuda:\n",
    "    train_nid = torch.from_numpy(train_nid).cuda()\n",
    "    print(\"GPU memory allocated before training(MB)\",\n",
    "            torch.cuda.memory_allocated(device=train_nid.device) / 1024 / 1024)\n",
    "start_time = time.time()\n",
    "best_f1 = -1\n",
    "\n",
    "h_loss_op = HLoss()\n",
    "js_loss_op = Jensen_Shannon()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                         Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "---------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                   initialize         3.81%     263.982ms        37.51%        2.601s        2.601s      83.900ms         1.21%        2.601s        2.601s           0 b    -327.46 Kb     633.00 Kb     303.00 Kb             1  \n",
      "                                   aten::item         2.90%     201.386ms        33.89%        2.350s      57.008us     142.677ms         2.05%        2.356s      57.159us           0 b           0 b           0 b           0 b         41223  \n",
      "                    aten::_local_scalar_dense        30.98%        2.149s        30.98%        2.149s      52.123us        2.214s        31.83%        2.214s      53.698us           0 b           0 b           0 b           0 b         41223  \n",
      "                    calculate_augmented_delta        10.34%     716.864ms        21.55%        1.495s      15.096ms     886.110ms        12.74%        1.499s      15.137ms           0 b        -360 b      87.40 Mb    -271.48 Mb            99  \n",
      "    calculate_ego_graph_message_passing_value         2.62%     181.590ms        15.99%        1.109s      11.198ms     228.571ms         3.29%        1.120s      11.309ms           0 b           0 b       8.49 Mb     -74.03 Mb            99  \n",
      "                                compute_model         2.53%     175.356ms        15.66%        1.086s      10.969ms      25.997ms         0.37%        1.114s      11.252ms           0 b           0 b     173.50 Kb     -33.80 Gb            99  \n",
      "                                     aten::to         0.41%      28.559ms        13.95%     967.578ms      86.414us      36.192ms         0.52%     555.866ms      49.644us       1.55 Kb           0 b     137.43 Mb           0 b         11197  \n",
      "                               aten::_to_copy         1.03%      71.090ms        13.54%     939.019ms     169.101us      38.329ms         0.55%     519.674ms      93.584us       1.55 Kb         236 b     137.43 Mb     198.00 Kb          5553  \n",
      "                                  aten::copy_        12.28%     851.905ms        12.28%     851.905ms     153.413us     469.831ms         6.76%     469.831ms      84.608us           0 b           0 b           0 b           0 b          5553  \n",
      "                                 aten::matmul         0.18%      12.557ms         8.58%     595.107ms     375.699us       7.286ms         0.10%     813.300ms     513.447us           0 b           0 b       3.08 Gb           0 b          1584  \n",
      "---------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 6.935s\n",
      "Self CUDA time total: 6.953s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "subg_t = []\n",
    "\n",
    "for epoch in range(args.n_epochs):\n",
    "    for j, subg in enumerate(loader):\n",
    "        if cuda:\n",
    "            subg = subg.to(DEVICE)\n",
    "\n",
    "        # Augment Subgraph\n",
    "        if epoch == 0:\n",
    "            current_subg = subg\n",
    "        else:\n",
    "            current_subg = subg_t[j]\n",
    "\n",
    "        # with profile(activities=[ProfilerActivity.CUDA, ProfilerActivity.CPU], record_shapes=True, profile_memory=True) as prof:\n",
    "        #     with record_function(\"generate_aug_graph\"):\n",
    "        auged_subg, delta_G_e, delta_G_v, delta_G_e_aug, delta_G_v_aug \\\n",
    "            = _generate_aug_graph(current_subg, model,\n",
    "                                    args.sigma_delta_e, args.sigma_delta_v, args.mu_e, args.mu_v,\n",
    "                                    args.lam1_e, args.lam1_v, args.lam2_e, args.lam2_v,\n",
    "                                    args.a_e, args.b_e, args.a_v, args.b_v)\n",
    "        if j == 0:\n",
    "            subg_t = []\n",
    "        \n",
    "        subg_t.append(auged_subg)\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
